\chapter{SQLAlchemy}

\section{Allgemeines}

SQLAlchemy\footnote{\href{http://www.sqlalchemy.org}{http://www.sqlalchemy.org}}
ist nicht nur ein ORM-System sondern eine Datenbankabstraktionsebene die auch
ORM kann - man kann es auch problemlos nutzen ohne auch nur ein einziges Objekt
zu mappen.

Das Framework besteht aus mehreren Modulen. Sie lassen sich grob in
\textbf{Dialects}, \textbf{Core} und \textbf{ORM} unterteilen.

Das \textbf{Dialects}-Modul ist dafür zuständig, auf die verschiedenen
Datenbanksysteme zuzugreifen - eine vollständige Liste der Datenbanksysteme und
der verschiedenen APIs (für MSSQL\footnote{Microsoft SQL Server} gibt es
beispielsweise 5 verschiedene APIs) findet man in der
SQLAlchemy-Dokumentation\footnote{\href
{http://www.sqlalchemy.org/docs/core/engines.html\#supported-dbapis}
{http://www.sqlalchemy.org/docs/core/engines.html\#supported-dbapis}}.
Er abstrahiert also den Zugriff auf die
verschiedenen Datenbanken vollständig, sodass anders als bei Pythons BB-API
abgesehen von den Verbindungsdaten keine unterschiedlichen Funktionsparameter
notwendig sind. Eine weitere Aufgabe des \emph{Dialects}-Moduls ist die
Abstraktion der Spaltentypen - die meisten Datenbanksystemen haben zusätzliche
Typen die nicht standardisiert sind; so hat PostgreSQL beispielsweise den
\emph{INET}-Datentyp um IP-Adressen zu speichern - dieser wird durch
\texttt{postgresql.INET} aus \texttt{sqlalchemy.dialects} repräsentiert.

Das \textbf{Core}-Modul enthält alle nicht-ORM-bezogenen Funktionen von
SQLAlchemy. Dazu gehört insbesondere die \emph{SQL Expression Language}, die dem
Entwickler ermöglicht, SQL zu erzeugen ohne selbst SQL zu schreiben, indem sie
die Bestandteile von SQL durch datenbanksystemunabhängige Python-Konstrukte
repräsentiert. Dabei ist es sowohl möglich, nur die Python-Konstrukte zu
benutzen oder einen String mit einer SQL-Abfrage zu übergeben, als auch beides
zu kombinieren. Die beiden letzteren Methoden sind allerdings u.U. nicht mehr
mit allen Datenbanksystemen kompatibel da man nicht ausschließlich die
Abstraktion benutzt sondern (teilweise) selbst SQL-Abfragen schreibt. Ein
weiterer wichtiger Teil vom \emph{Core} ist der Verbindungsaufbau anhand eines
Connectionstrings, der alle benötigten Daten einschließlich Datenbanksystem und
-API enthält. Ebenfalls vom \emph{Core} zur Verfügung gestellt wird der
Connection-Pool, der bereits aufgebaute Datenbankverbindungen enthält sodass
eine Applikation schnell an eine Verbindung kommt ohne erst eine neue Verbindung
aufbauen zu müssen, was je nach Datenbanksystem ein relativ "teurer" Prozess
ist.

Das dritte und wichtigste Modul ist das \textbf{ORM}-Modul. Im Gegensatz zum
Lowlevel-Zugriff den die \emph{SQL Expression Language} bietet ist das ORM auf
einer hohen Ebene angesiedelt und bietet eine starke Abstraktion. Dazu bietet es
verschiedene Möglichkeiten, Datenbanktabellen und Objekte miteinander zu
verbinden - zum einen den \emph{mapper} umd zum anderen die \emph{declarative
syntax}. Ebenfalls im \emph{ORM}-Modul enthalten ist die
\emph{\texttt{relationship()} API}, mit der man Relationen zwischen mehreren
Tabellen mappen kann.


\section{Datenbankdefinition}

Wie bereits erwähnt gibt es zwei Möglichkeiten, die Datenbankstruktur und das
dazugehörige Mapping zu definieren. Als Beispiel für die beiden Möglichkeiten
wird jeweils die folgende Beispieldatenbank dienen:

\ul{Tabelle \textbf{authors}:}\\
\textbf{id} \texttt{INTEGER NOT NULL}\\
name \texttt{VARCHAR NOT NULL}

\ul{Tabelle \textbf{books}:}\\
\textbf{id} \texttt{INTEGER NOT NULL}\\
\textit{author\_id} \texttt{INTEGER NOT NULL}\\
title \texttt{VARCHAR NOT NULL}

\ul{Tabelle \textbf{tags}:}\\
\textbf{id} \texttt{INTEGER NOT NULL}\\
tag \texttt{VARCHAR UNIQUE NOT NULL}

\ul{Tabelle \textbf{tags2books}:}\\
\textbf{\textit{tag\_id}} \texttt{INTEGER NOT NULL}\\
\textbf{\textit{book\_id}} \texttt{INTEGER NOT NULL}

\ul{Fremdschl\"ussel-Beziehungen:}\\
books.author\_id $\rightarrow$ authors.id\\
tags2books.tag\_id $\rightarrow$ tags.id\\
tags2books.author\_id $\rightarrow$ authors.id

Bei den Primärschlüsseln in \emph{authors}, \emph{books} und \emph{tags} sollen
darüberhinaus automatisch generierte IDs benutzt werden.

\bild{database.pdf}{0.75\textwidth}{Datenbankmodell}{Datenbankmodell}

\subsection{mapper()-Syntax}

Nutzt man die klassische \emph{mapper()-Syntax} so definiert man Tabellen,
Klassen und Mappings/Relationen nacheinander.
\autoref{lst:dbdef-mapper-tables} zeigt die Definition der Tabellen und
datenbankseitigen Relationen (Fremdschlüssel, Indizes). Im zuvor erzeugten
\texttt{metadata}-Objekt legt SQLAlchemy die Metadaten zu den Tabellen und
Relationen ab. Desweiteren kann man über dieses Objekt die Tabellen in der
Datenbank erstellen (\texttt{metadata.create\_all()}) und auch löschen lassen.
Da die \emph{id}-Spalten als \texttt{Integer} und \texttt{primary\_key}
definiert sind generiert SQLAlchemy automatisch eine automatisch
inkrementierende Spalte - d.h. in PostgreSQL eine Spalte vom Typ \texttt{serial}
und in MySQL eine \texttt{INT}-Spalte mit dem \texttt{AUTO\_INCREMENT}-Attribut.
Damit die Spalten nicht \texttt{NULL} sein dürfen wurde bei allen
nicht-Primärschlüssel-Spalten das \texttt{nullable}-Attribut auf \texttt{False}
gesetzt. Bei den Primärschlüsseln ist dies nicht notwendig, da ein
Primärschlüssel \textit{per definitionem} nicht \texttt{NULL} sein kann.
Ebenfalls in der Tabellendefinition enthalten sind Fremdschlüssel, die mit dem
\texttt{ForeignKey()}-Konstrukt definiert werden, und reguläre Indizes, die mit
\texttt{index=True} definiert werden.

\lstinputlisting[language=Python,label=lst:dbdef-mapper-tables,lastline=30,
caption=Definition der Tabellen]{code/sqlalchemy-def-mapper.py}

In \autoref{lst:dbdef-mapper-classes} werden die Klassen für das Mapping
definiert. Bei diesen Klassen handelt es sich um POPOs\footnote{Plain Old Python
Objects}, die nur von \texttt{object} erben und auch keine anderen Bedingungen
erfüllen müssen - eine komplett leere Klasse reicht bereits aus. Zum Testen und
Debuggen ist es jedoch sinnvoll, die \texttt{\_\_repr\_\_}-Methode zu
implementieren, sodass \texttt{print instanz\_der\_klasse} brauchbare
Informationen anstelle der Speicheradresse ausgibt. Im Beispielcode werden dazu
einfach der Klassename und sowohl die ID als auch die aussagekräftigste Spalte
(Name, Titel, Tagname) verwendet. In einem realen Projekt wäre es darüberhinaus
sinnvoll einen Konstruktor zu erstellen, der häufig genutzten Feldern einen Wert
zuweist, sodass man z.B. \texttt{jquery\_tag = Tag('jquery')} schreiben kann.

\lstinputlisting[language=Python,label=lst:dbdef-mapper-classes,firstline=32,
lastline=43,caption=Definition der Klassen]{code/sqlalchemy-def-mapper.py}

Nachdem Tabellen und Klassen definiert sind müssen sie miteinander verknüpft
werden - bisher sind die Klassen relativ nutzlos.
\autoref{lst:dbdef-mapper-mapping} zeigt den dafür notwendigen Code. Die
\texttt{mapper()}-Funktion nimmt als Argumente als erstes die zu mappende Klasse
und als zweites die dazugehörige Tabelle. Relationen zwischen Tabellen werden
über den \texttt{properties}-Parameter und die \texttt{relationship()}-Funktion
definiert. Diese Funktion benötigt als ersten Parameter das Ziel der Relation.
Um auch vom Zielobjekt aus auf die Relation zugreifen zu können kann man über
den \texttt{backref}-Parameter den Feldnamen angeben, unter dem sie dort
verfügbar sein soll. Sofern man die \emph{backref} konfigurieren will, gibt
man statt eines Strings den Rückgabewert der \texttt{backref()}-Funktion an, die
als ersten Parameter den Feldnamen und danach diverse Konfigurationsparameter
erwartet. Der wohl wichtigste Parameter sowohl von \texttt{relationship()} als
auch \texttt{backref()} ist \texttt{lazy}: Er gibt an, zu welchem Zeitpunkt die
Daten der Relation geladen werden sollen. Standard ist \texttt{True}, was
bedeutet, dass eine SQL-Abfrage abgeschickt wird sobald auf die Relation
zugegriffen wird. Wenn man \texttt{lazy=False} setzt wird die Query, die die
Daten des Objektes selbst lädt, um einen \emph{JOIN} erweitert, sodass beim
Zugriff auf die Relation keine weitere Abfrage mehr notwendig ist - im Beispiel
wurde \texttt{Tag.books} auf \emph{eager loading} (\texttt{lazy=False}) gesetzt,
da es anzunehmen ist, dass man nicht nur ein Tag laden will sondern auch die
Bücher, die dieses Tag haben. Der letzte wichtige Parameter ist
\texttt{secondary} und wird für \emph{Many-To-Many}-Relationen benutzt, um die
Assoziationstabelle anzugeben.

\lstinputlisting[language=Python,label=lst:dbdef-mapper-mapping,firstline=45,
lastline=52,caption=Mapping der Tabellen auf die
Klassen]{code/sqlalchemy-def-mapper.py}


\subsection{Deklarative Syntax}

Die grundlegenden Methoden sind bei der deklarativen Syntax mit denen der
\texttt{mapper()}-Syntax identisch: Relationen werden ebenfalls mit
\texttt{relationship()} und Spalten mit \texttt{Column()} definiert, was man in
\autoref{lst:dbdef-decl} leicht erkennt.
Allerdings sind weder \texttt{mapper()}-Aufrufe noch reine Tabellendefinitionen
notwendig - man definiert einfach eine Klasse, die von der durch
\texttt{declarative\_base()} erzeugten Klasse erbt und Felder mit den
Spaltennamen enthält. im \texttt{Column()}-Aufruf fällt der Spaltenname dafür
weg, da er ja schon durch den Feldnamen angegeben wurde. Der Tabellenname in der
Datenbank wird mit dem "magischen" Feld \texttt{\_\_tablename\_\_} angegeben;
desweiteren können Parameter, die normalerweise an \texttt{mapper()} übergeben
würden, mit \texttt{\_\_mapper\_args\_\_} festgelegt werden.
Da bei Relationen u.U. die referenzierte Klasse bzw. Tabelle noch nicht definiert
wurde ist es auch möglich, ihren Namen als String zu übergeben - dadurch ist es
möglich, im Beispielcode in der Deklaration von \emph{Book} schon die
\emph{Tag}-Klasse und die \emph{tags2books}-Tabelle zu referenzieren obwohl sie
noch nicht definiert wurden.
Ein arbeitssparendes Feature der deklarativen Syntax ist der Konstruktor, den
jede Klasse erhält: Er weist jedes übergebene \textit{keyword argument} dem
gleichnamigen Feld zu, d.h. man kann beispielsweise einen neuen Autor mittels
\texttt{Author(name='Donald Knuth')} anlegen statt erst das Objekt instanziieren
zu müssen und danach \texttt{autor.name} zuzuweisen.

\lstinputlisting[language=Python,label=lst:dbdef-decl,caption=Deklarative
Datenbankdefinition]{code/sqlalchemy-def-decl.py}


\section{Datenbankzugriff}

In der Datenbankdefinition wurde bisher noch keine Datenbank angegeben
geschweige denn eine Verbindung aufgebaut. Damit SQLAlchemy eine Verbindung
aufbauen und für die jeweilige Datenbank gültiges SQL generieren kann, ist es
notwendig, das \emph{metadata}-Objekt mit einer \emph{engine} zu verbinden. Dies
geschieht über die \texttt{bind}-Eigenschaft von \emph{metadata}. In
\autoref{lst:engine-bind} wird eine Verbindung zu \emph{postgresql:///test}
aufgebaut, d.h. zu einer PostgreSQL-Datenbank namens \emph{test}, die ohne
weitere Authentifizierung erreichbar ist. Sofern Benutzername, Passwort oder
andere Parameter notwendig sind, werden sie in derselben Art und Weise
angegeben, die auch bei anderen URLs - z.B. bei Weblinks - üblich ist: \\
\texttt{dialect://user:password@host/dbname[?key=value..]} \\
Der \texttt{echo=True}-Parameter von \texttt{create\_engine()} gibt an, dass
jegliche SQL-Abfragen auf \emph{stdout} ausgegeben werden, was insbesondere bei
der Entwicklung nützlich ist, um beispielsweise erkennen zu können ob man
durch Relationen mit \emph{lazy loading} zusätzliche Abfragen verursacht.
Nachdem \emph{metadata} nun eine \emph{engine} besitzt, können die definierten
Tabellen mit \texttt{metadata.create\_all()} erstellt werden.

\lstinputlisting[language=Python,label=lst:engine-bind,caption=Verbindung zur
Datenbank]{code/sqlalchemy-engine-bind.py}

\subsection{Zugriff via ORM}\label{sqlalchemy-orm}

Um per ORM auf die Datenbank zugreifen zu können, ist nicht nur die
Datenbankverbindung in Form einer \emph{engine} notwendig, sondern auch eine
\emph{session}. Die dazu notwendige Klasse wird mit der Funktion
\texttt{sessionmaker()} erstellt, die als Parameter die \emph{engine} erwartet.
Ein weiterer Parameter, der in \autoref{lst:session} benutzt wird, ist
\texttt{autocommit}. Wenn \texttt{autocommit} deaktiviert ist, startet
SQLAlchemy automatisch eine Transaktion, sobald auf die Datenbank zugegriffen
wird, sodass man Änderungen mit \texttt{session.commit()} bestätigen bzw. mit
\texttt{session.rollback()} rückgängig machen muss. Es ist nicht zu empfehlen,
\texttt{autocommit} zu aktivieren, da man dann nach Änderungen an einem Objekt
nicht erwarten kann, dass diese sofort in der Datenbank persistiert werden.
Die kann problematisch sein, wenn eine Applikation direkt nach einer Änderung
ein externes Programm aufruft, welches ebenfalls auf die Datenbank zugreift
und die geänderten Daten benutzen soll.

\lstinputlisting[language=Python,label=lst:session,caption=Erstellen der
Session]{code/sqlalchemy-session.py}

Jegliche Änderungen an der Datenbank, die über das ORM durchgeführt werden
sollen, benötigen eine Instanz eines gemappten Objektes.

Wenn man ein neues Objekt in die Datenbank einfügen möchte, erstellt man einfach
eine neue Objektinstanz und fügt es mittels \texttt{session.add(objekt)} der
Session hinzu. Sofern man nicht mit \emph{autocommit} arbeitet ist danach noch
ein Aufruf von \texttt{session.commit()} notwendig, um das Objekt tatsächlich in
der Datenbank zu speichern. Falls das neue Objekt andere noch nicht persistierte
Objekte referenziert, müssen diese nicht separat der Session hinzugefügt werden;
SQLAlchemy persistiert automatisch alle Objekte, die von einem neuen Objekt
referenziert werden. \autoref{lst:orm-add} demonstriert dieses Feature, indem
verschiedene Objekte angelegt werden und auf verschiedene Arten miteinander
verknüpft werden:
Die einfachste Methode ist, einfach dem entsprechenden Feld das zu verknüpfende
Objekt zuzuweisen: \texttt{author=jresig} \\
Im Falle der M:N-Relation \emph{Book.tags} handelt es sich beim
\texttt{tags}-Feld um eine Liste. Daher muss in diesem Fall eine Liste statt
eines einzelnen Objekts zugewiesen oder eine entsprechende Listenoperation
wie \texttt{.add(objekt)} verwendet werden. Da die \emph{Book.tags}-Relation
mit einen \textit{backref} \texttt{Tag.books} definiert wurde, kann
\texttt{jsbook} nun auch über die Liste \texttt{jquery.books} referenziert und
auch verändert werden. Um nun noch ein Tag \emph{javascript} zu erstellen und es
mit dem neuen Buch zu verknüpfen, könnte man es einfach der
\texttt{jsbook.tags}-Liste hinzufügen. Allerdings ist es auch umgekehrt möglich,
indem man das Buch der \texttt{books}-Liste des neuen Tags hinzufügt. Obwohl die
Tag-Instanz nirgends zugewiesen wurde wird sie durch die Relation
\texttt{Tag.books} und die dazugehörige \texttt{Book.tags}-Relation mit dem Buch
verknüpft und daher korrekt persistiert.

\lstinputlisting[language=Python,label=lst:orm-add,caption=Persistieren von
Objekten]{code/sqlalchemy-orm-add.py}

Das Löschen von Objekten geschieht wie auch das Hinzufügen über die
\texttt{delete()}-Methode der Session. Allerdings sollte man dazu logischerweise ein
bereits persistiertes Objekt haben. Da man normalerweise keine Objekte löschen
will die man gerade erst erstellt hat und es ineffizient wäre, ein Objekt aus
der Datenbank zu \texttt{SELECT}en nur um es zu löschen, hat das
\texttt{Query}-Objekt ebenfalls eine \texttt{delete()}-Methode, sodass man auch
ohne eine Instanz eines gemappten Objektes Daten löschen kann.

Die wichtigste Operation bei einer Datenbank ist das Auslesen und Verändern von
Daten - schließlich würde es nicht viel bringen, Daten in einer Datenbank
abzulegen, wenn man sie nicht mehr auslesen oder verändern könnte. Zum Auslesen
von Daten benötigt man das im letzten Absatz bereits erwähnte
\texttt{Query}-Objekt. Um eine Instanz dazu bekommen, benutzt man die Methode
\texttt{session.query()} und übergibt ihr als Parameter die Mapping-Klassen, aus
deren Tabellen man Daten abrufen will. Dieses Objekt kann nun durch Filter,
Sortierungen, Optionen, Joins, Limits usw. erweitert werden, die die vom Objekt
repräsentierte SQL-Abfrage beinflussen. Wenn das Query-Objekt so konfiguriert
ist, dass es der gewünschten Datenbankoperation entspricht - das kann auch ein
"nacktes" Query-Objekt ohne jegliche Modifikatoren sein, sofern man alle Zeilen
unsortiert abrufen möchte - kann man die Query auf verschiedene Arten ausführen:
\begin{itemize}
\item \texttt{.all()} führt eine \texttt{SELECT}-Query aus und gibt eine Liste
aller gefundenen Zeilen zurück.

\item Wenn man über das Query-Objekt iteriert wird die Query implizit
ausgeführt, als ob \texttt{.all()} aufgerufen worden wäre.

\item \texttt{.first()} führt eine \texttt{SELECT}-Query aus und gibt die erste
gefundene Zeile oder \texttt{None} zurück.

\item \texttt{.one()} führt eine \texttt{SELECT}-Query aus und gibt die einzige
gefundene Zeile zurück oder wirft eine \texttt{NoResultFound} bzw.
\texttt{MultipleResultsFound}-Exception.

\item \texttt{.get(key)} verhält sich wie \texttt{.first()}, fügt allerdings
zuvor einen Filter hinzu sodass nur die Zeile abgerufen wird, deren
Primärschlüssel \texttt{key} entspricht.

\item \texttt{.count()} führt eine \texttt{SELECT COUNT}-Query aus und gibt die
Anzahl der gefundenen Zeilen zurück.

\item \texttt{.delete()} führt eine \texttt{DELETE}-Query aus und gibt die
Anzahl der gelöschten Zeilen zurück.

\item \texttt{.update(values)} führt eine \texttt{UPDATE}-Query aus;
\texttt{values} ist dabei ein \texttt{dict} welches die zu aktualisierenden
Felder als \emph{Key} und Werte bzw. SQL-Ausdrücke als \emph{Value} enthält.
Zurückgegeben wird die Anzahl der veränderten Zeilen.
\end{itemize}

Allerdings will man in den wenigsten Fällen eine Operation auf alle Datensätze
anwenden. Daher wird man meistens die schon angesprochenen Modifikatoren
benutzen, bevor man die Query ausführt. Die Modifier haben ein generatives
Interface, d.h. jede Modifier-Funktion gibt ein neues \texttt{Query}-Object
zurück, welches eine Kopie das ursprünglichen Objekts ist, die allerdings um die
Optionen bzw. Kriterien des Modifiers erweitert wurde.

\begin{itemize}
\item Der einfachste Modifier ist \texttt{distinct()}. Er fügt der Query einfach
das \texttt{DISTINCT}-Schlüsselwort hinzu.


\item Sofern man selbst SQL-Statements schreiben möchte, kann man dies mithilfe
des \texttt{from\_statement()}-Modifiers tun, der als Parameter einfach eine
vollständige SQL-Abfrage erwartet. Sofern man Parameter in seiner Abfrage
benutzt, kann man diese danach mit dem \texttt{params()}-Modifier angeben,
welcher ein \texttt{dict} als Parameter erwartet.


\item Für simple \emph{Spalte==Wert}-Filter ist der
\texttt{filter\_by()}-Modifier geeignet. Man übergibt ihm die Spaltennamen und
Werte als \textit{keyword arguments} und der Modifier verknüpft sie automatisch
mit \texttt{AND}. Wenn die Query bereits WHERE-Filter enthält, so werden die
neuen Filter mit den alten ebenfalls per \texttt{AND} verknüpft.


\item Komplexe Filter erstellt man mit dem \texttt{filter()}-Modifier. Zum einen
kann man ihm einen SQL-String übergeben, wie er auch in einer händisch
geschriebenen Abfrage in der WHERE-Bedingung auftreten könnte. Da dies aber
nicht im Sinne eines ORM ist, sollte man eher die von SQLAlchemy zur Verfügung
gestellten \emph{clause constructs} nutzen. Mit diesen kann man mit einer
Syntax, die der normalen Python-Syntax nahe kommt, bool'sche Ausdrücke
definieren: Die Tabellenspalte gibt man in der Form \texttt{Objekt.feld} an; den
zu vergleichenden Wert gibt man einfach als String an. Um mehrere Operanden zu
verknüpfen wurden die bitweisen Verknüpfungsoperatoren \texttt{\&} und
\texttt{|} überladen. Aufgrund der Operatorenpriorität (bitweise Operatoren binden
stärker als Vergleichsoperatoren) ist es dabei allerdings notwendig, den
Ausdruck wie in \autoref{lst:op-precedence} zu klammern.
\begin{lstlisting}[language=Python,label=lst:op-precedence,caption=Korrekte
Klammerung]
# Falsch:
.filter(Obj.colA == 123 | Obj.colB >= 456)
# Richtig:
.filter((Obj.colA == 123) | (Obj.colB >= 456))
\end{lstlisting}

Eine Alternative zu \texttt{\&} und \texttt{|} sind die Funktionen
\texttt{and\_()} und \texttt{or\_()}. Sie verknüpfen alle ihre Parameter mit
\texttt{AND} bzw. \texttt{OR}. Da man seine Ausdrücke dadurch allerdings in
Polnischer Notation\footnote{Schreibweise für Ausdrücke, in der die Operanden
nach dem Operator kommen.} schreibt, senkt diese Variante die Lesbarkeit des
Codes. Daher ist es im Allgemeinen sinnvoller, die überladenen Operatoren zu
benutzen und sauber zu Klammern.

Wenn die Filter auf der obersten Ebene nur aus Konjunktionen bestehen kann man
sie auch einfach auf mehrere \texttt{filter()}-Aufrufe verteilen - wie schon bei
\texttt{filter\_by{}} werden die neuen Filter mit den alten per \texttt{AND}
verknüpft.

Neben Vergleichen sind auch andere Operatoren möglich. Der vermutlich Wichtigste
ist dabei der \texttt{IN}-Operator, mit dem man überprüft, ob eine Spalte einen
Wert aus einer Liste von Werten hat. Da man in Python den \texttt{in}-Operator
nicht überladen kann, ist er durch die Methode \texttt{Obj.col.in\_(lst)}
realisiert, wobei \texttt{lst} die Liste der Werte ist.
Wenn man einen Operator benutzen will, den SQLAlchemy nicht kennt, kann man ihn
mit der \texttt{Obj.col.op(oper)(arg)}-Methode aufrufen, wobei \texttt{oper} der
Operator und \texttt{arg} der rechte Operand ist.


\item Um die Anzahl der zurückgegebenen Zeilen zu beschränken benutzt man den
\texttt{limit()}-Modifier. Sein einziger Parameter ist die maximale
Zeilananzahl.


\item Insbesondere in Verbindung mit dem \texttt{limit()}-Modifier will man
oftmals auch eine gewisse Anzahl an Zeilen überspringen - beispielsweise um
seitenweise durch eine große Menge Datensätze navigieren zu können. Dazu benutzt
man den \texttt{offset()}-Modifier und übergibt ihm die Anzahl der zu
überspringenden Zeilen als Parameter.


\item Um die Datensätze bereits datenbankseitig zu sortieren gibt es den
\texttt{order\_by()}-Modifier. Er akzeptiert genau wie \texttt{filter()} ein
\emph{clause construct}, allerdings übergibt man normalerweise nur eine oder
mehrere Spalten in der in der Form \texttt{Obj.col} bzw. \texttt{Obj.col.desc()}
wenn man absteigend sortieren will.


\item Ein insbesondere im Zusammenhang mit Relationen häufig genutzter Modifier
ist \texttt{options()}, mit dem man verschiedene Mapper-Optionen festlegen kann.
Dazu gehören insbesondere die Optionen \texttt{joinedload()} bzw.
\texttt{joinedload\_all()} und \texttt{lazyload()}, die für die übergebenen
Relationen die jeweilige Ladestrategie einstellen. \texttt{joinedload\_all()}
aktiviert die Strategie für alle übergebenen Relationen; die normale Funktion nur
die letzte übergebene Relation - die vorherigen sind in diesem Fall dazu notwendig,
um den "Pfad" zur zu konfigurierenden Relation anzugeben.

\item Wenn man anhand einer Spalte aus einer Relation filtern möchte, so muss
man die Relation explizit joinen. Dazu dient der \texttt{join()}-Modifier dem
man als Parameter entweder den Namen der Relation als String oder das Feld im
Mappingobjekt in der Form \texttt{Obj.col} übergibt.

\end{itemize}

In \autoref{lst:orm-select} werden verschiedene Modifier genutzt, um alle Bücher
eines Autors und die Tags dieser Bücher in einer einzigen Query abzurufen. Da
sowohl \texttt{Author.books} als auch \texttt{Book.tags} nicht für
\emph{eager-loading} konfiguriert wurde, muss dies per \texttt{options()} im
\texttt{Query}-Objekt gemacht werden. Desweiteren wird mittels
\texttt{filter\_by()} nur ein bestimmer Autor ausgelesen. Da im Beispielcode
angeonmmen wird, dass der Autor immer existiert, wird die Query mit
\texttt{one()} gestartet, sodass es eine Exception gegeben würde, wenn dem nicht
so wäre.

\lstinputlisting[language=Python,label=lst:orm-select,caption=Abrufen von
Daten]{code/sqlalchemy-orm-select.py}

\autoref{lst:orm-select-join} zeigt, wie man mit SQLAlchemy Daten ausliest und
anhand einer Spalte aus einer anderen Tabelle, die über eine Relation verknüpft
ist, filtert. Mittels des \texttt{join()}-Modifiers wird die
\emph{Book.tags}-Relation in die Abfrage eingefügt. Danach wird - um nicht pro
Buch beim Anzeigen der Tags eine weitere Abfrage an die Datenbank schicken zu
müssen - wie bereits in \autoref{lst:orm-select} \emph{eager-loading} für die
\texttt{Book.tags}-Relation aktiviert. Beim Filtern wird dieses mal in
\texttt{filter()} explizit angegeben, dass sich der Filter auf \texttt{Tag.tag}
bezieht - allerdings könnte man auch \texttt{filter\_by(tag='jquery')} nutzen,
da der Bezeichner \texttt{tag} eindeutig ist. Da es durchaus mehrere Bücher mit
einem bestimmten Tag geben kann, wird nun per Iterator auf die Query zugegriffen
und jedes gefundene Buch und seine Tags ausggeben.

\lstinputlisting[language=Python,label=lst:orm-select-join,caption=Filtern von
Daten anhand einer Relation]{code/sqlalchemy-orm-select-join.py}

Um Daten zu verändern, benötigt man die dazugehörige Instanz des
Mapping-Objekts. Dort kann man einfach die Felder ändern. Bei Relationen sind
die Felder Listen, d.h. man kann nicht nur eine neue Liste zuweisen sondern auch
einzelne Elemente hinzufügen/löschen. Wie auch bei allen anderen Veränderungen
an der Datenbank ist es hier notwendig, am Ende \texttt{session.commit()}
auszuführen, um sie zu bestätigen. Alternativ kann man sie natürlich auch mit
\texttt{session.rollback()} rückgängig machen.

In \autoref{lst:orm-modify} werden einem \texttt{Book}-Objekt zwei Tags
hinzugefügt: ein bereits vorhandener, der daher erst aus der Datenbank
ausgelesen werden muss, und ein neuer, der beim Commit der Änderungen
automatisch erstellt wird.

\lstinputlisting[language=Python,label=lst:orm-modify,caption=Ver\"andern von
Daten]{code/sqlalchemy-orm-modify.py}

\subsection{Lowlevel-Zugriff}

Mithilfe der \emph{SQLAlchemy Expression Language} ist es möglich, auf einer
sehr datenbanknahen Ebene auf die Daten zuzugreifen und sie zu verändern. Dazu
benötigt man wie auch für den ORM-Zugriff Tabellendefinitionen, sodass
SQLAlchemy die Datenbankstruktur kennt.
Die Tabellendefinitionen bieten darüberhinaus die zur Datenveränderung
notwendigen Methoden an.

\begin{itemize}

\item \texttt{select()} aus dem Modul \texttt{sqlalchemy.sql} nimmt als ersten
Parameter eine Liste der Spalten, die vom \texttt{SELECT} ausgelesen werden
sollen. Sofern man alle Spalten aus einer einzigen Tabelle auslesen möchte, kann
man alternativ einfach \texttt{table.select()} nutzen.
Um das Ergebnis zu filtern, kann man als zweiten (bzw. bei der Alternativsyntax
als ersten) Parameter ein \emph{clause construct} übergeben. Die Syntax dabei
ist mit der vom \texttt{filter()}-ORM-Modifier identisch, allerdings müssen
Spaltennamen explizit in der Form \texttt{table.c.col} angegeben werden, wobei
\texttt{table} das \texttt{Table}-Objekt der Tabellendefintion und \texttt{col}
der Spaltenname ist. Anstelle des Parameters kann man auch die
\texttt{where()}-Methode des von \texttt{select()} zurückgegebenen Objekts
benutzen. Wenn man \texttt{JOIN}s nutzt, jedoch nicht alle Spalten aller
Tabellen auslesen will, so kann man mit dem \texttt{from\_obj}-Parameter eine
Liste der Quelltabellen angeben. Bei einfachen \texttt{JOIN}s hat die Liste
normalerweise nur ein Element, welches man mittels
\texttt{table.join(table2).join(table3)} erzeugt. Die \texttt{ON}-Bedingungen
der Joins werden dabei automatisch anhand der definierten Fremdschlüssel
gebildet. Wenn man andere Bedingungen möchte kann man diese allerdings auch als
zusätzlichen Parameter an \texttt{join()} übergeben.

\item \texttt{table.insert()} erzeugt ein \texttt{INSERT}-Statement. Um es
auszuführen ruft man die \texttt{execute()}-Methode des von \texttt{insert()}
zurückgegebenen Objekts auf und übergibt ihr die Spaltenwerte als
\texttt{keyword arguments}. Um mehrere Zeilen auf einmal einzufügen kann man
auch eine Liste übergeben, die für jede Zeile ein \texttt{dict} mit den
Spaltenwerten enthält.

\item \texttt{table.update()} verhält sich ähnlich wie \texttt{table.insert()}
mit dem Unterschied, dass es ein \texttt{UPDATE}-Statement erzeugt welches eine
\texttt{where()}-Methode hat um nur ausgewählte Zeilen zu verändern.

\item \texttt{table.delete()} erzeugt ein \texttt{DELETE}-Statement. Um nicht
alle Zeilen zu löschen sollte man mit der \texttt{where()}-Methode des
Statements einen Filter angeben bevor man es mit \texttt{execute()} ausführt.
\end{itemize}

\autoref{lst:low-insert} zeigt gut, wie aufwändig eine einfache Operation -
einen Autor und ein Buch mit einem bereits existierenden Tag anzulegen - ohne
ORM ist. Dieselbe Operation ließe sich mit vier Zeilen ORM-Code realisieren der
quasi genauso effizient aber sehr viel lesbarer wäre.
Beim Einfügen einer Zeile wird ein \texttt{ResultProxy} zurückgegeben, aus dem
man die ID in Form eines Primärschlüssel-Tupels erhält - obwohl der
Primärschlüssel nur aus einer einzigen Spalte besteht muss man ihn manuell aus
dem Tupel extrahieren. Beim Auslesen der Tag-ID müssen die Spalten nun mit ihrem
vollen Namen referenziert werden; es reicht nicht mehr aus, nur den Spaltennamen
anzugeben. Da wir auf einer sehr niedrigen Ebene arbeiten bietet SQLAlchemy nun
auch keine Möglichkeit an, Tag und Buch automatisch zu verknüpfen - auch dazu
muss manuell ein SQL-Statement ausgeführt werden.

\lstinputlisting[language=Python,label=lst:low-insert,caption=Einf\"ugen von
Daten ohne ORM]{code/sqlalchemy-low-insert.py}

Der Code in \autoref{lst:low-select} liest wie sein ORM-Pendant in in
\autoref{lst:orm-select-join} alle Bücher mit einem bestimmten Tag aus. Da man
außer den Fremdschlüsseln keine Relationen hat muss man manuell angeben, wie
Bücher und Tags miteinander verknüpft werden - allerdings hilft SQLAlchemy
insofern, dass die Joins nur definiert werden müssen und die Bedingungen
automatisch generiert werden. Zum Filtern der Ergebnisse wird diesmal die besser
verständliche \texttt{where()}-Syntax statt des \texttt{select()}-Parameters
verwendet. Nach dem Ausführen der Query mittels \texttt{execute()} kann über die
Zeilen iteriert werden.

\lstinputlisting[language=Python,label=lst:low-select,caption=Auslesen von Daten
aus verkn\"upften Tabellen ohne ORM]{code/sqlalchemy-low-select.py}

\section{Deklarationsfreies ORM mit SqlSoup}

Oftmals muss man mit einer bereits vorhandenen Datenbank arbeiten, die entweder
mit einem anderen ORM wie z.B. Hibernate oder Propel oder aber manuell erstellt
wurde. Je nach Tabellenanzahl ist es in diesem Fall z.T. sehr aufwändig, eine
SQLAlchemy-kompatible Datenbankdefinition zu erstellen; insbesondere wenn man
die bestehende Software nicht auf SQLAlchemy umstellen will sondern nur auf die
Datenbank davon zugreifen will. Für solche Fälle gibt es die
\emph{SqlSoup}-Extension. Diese liest die Datenbankstruktur einschließlich
Fremdschlüsseln mittels Reflection aus und generiert daraus Mapping-Klassen die
einen sehr einfachen Zugriff auf die Datenbank ermöglichen - allerdings wird in
der Dokumentation von \emph{SqlSoup} explizit darauf hingewisen dass man außer
für sehr triviale Aufgaben das "richtige" ORM-System anstelle von \emph{SqlSoup}
benutzen soll. Insbesondere in Kommandozeilenprogrammen und Webanwendungen, wo
je nach Framework der gesamte Code regelmäßig ausgeführt werden muss, ist zu
bedenken dass \emph{SqlSoup} sehr viele Abfragen benötigt, um die
Datenbankstruktur herauszufinden während SQLAlchemy bei einer sauberen
Definition bereits alle benötigten Informationen hat und keine Datenbankzugriffe
dafür notwendig sind.

In \autoref{lst:sqlsoup-init} wird eine Verbindung zur Datenbank aufgebaut und
danach \emph{SqlSoup} initialisiert. Da eine Datenbank zwar Fremdschlüssel aber
keine komplexen Relationsdefinitionen enthalten kann, müssen diese manuell im
Code definiert werden. Die Syntax von \texttt{db.table.relate()} enspricht dabei
im Groben der von \texttt{relationship()} aus dem ORM-Modul. Es ist zu beachten,
dass die Relationsziele bei SqlSoup in der Form \texttt{db.table} angegeben
werden und die Tabellendefinitionen, die man bei Many-to-Many-Relationen für die
Assoziationstabelle benötigt, im Feld \texttt{\_table} von \texttt{db.table}
liegen.

\lstinputlisting[language=Python,label=lst:sqlsoup-init,caption=Initialisieren
von SqlSoup]{code/sqlsoup-init.py}

Wie \autoref{lst:sqlsoup-select} zeigt, geschieht das Auslesen von Daten mittels
SqlSoup geschieht analog zum Auslesen via SQLAlchemy/ORM. Der einzige
Unterschied ist, dass man nicht \texttt{session.query()} sondern
\texttt{db.table} als Query-Objekt nutzt. An der Modifier-Syntax und dem Zugriff
auf die Daten ändert sich nichts - abgesehen von der anderen Parametersyntax die
aber nur daher kommt, dass die Mapping-Klassen nicht mehr global definiert sind
sondern innerhalb vom \texttt{SqlSoup}-Objekt \texttt{db} liegen.

\lstinputlisting[language=Python,label=lst:sqlsoup-select,caption=Auslesen von
Daten mit SqlSoup]{code/sqlsoup-select.py}

Zum Modifizieren und Löschen von Daten benutzt man wie auch schon im regulären
SQLAlchemy normalerweise Instanzen der Mapping-Objekte. Allerdings benutzt man
statt \texttt{session.delete()} nun \texttt{db.delete()} und auch die
Transaktionsfunktionen \texttt{commit()} und \texttt{rollback()} werden in
SqlSoup über das von \texttt{SqlSoup()} erstellte \texttt{db}-Objekt ausgeführt.

Die Syntax zum Persistieren neuer Objekte unterscheidet sich von der bereits
bekannten insofern, dass man kein neues Objekt erstellt und dieses dann mittels
\texttt{session.add()} der Datenbank hinzufügt sondern
\texttt{db.table.insert()} nutzt und dieser Methode die Spaltenwerte als
\textit{keyword arguments} übergibt. \autoref{lst:sqlsoup-ins-del} nutzt diese
Methode, um einen neuen Autoren anzulegen, der danach allerdings sofort wieder
gelöscht wird. Der Commit zwischen Anlegen und Löschen ist notwendig, da
SQLAlchemy den Versuch, ein nicht persistiertes Objekt zu löschen, mit einer
\texttt{InvalidRequestError}-Exception ablehnt.

\lstinputlisting[language=Python,label=lst:sqlsoup-ins-del,caption=Einf\"ugen
und L\"oschen von Daten mit SqlSoup]{code/sqlsoup-ins-del.py}
